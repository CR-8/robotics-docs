---
title: AI Logic & Decision Making
description: Artificial intelligence for autonomous robot behavior
---

# AI Logic & Decision Making

AI enables robots to make intelligent decisions, learn from experience, and adapt to changing environments.

## Machine Learning in Robotics

### Supervised Learning

**Applications**:
- Object recognition
- Gesture classification
- Terrain classification

```python
from sklearn.ensemble import RandomForestClassifier
import numpy as np

# Train classifier for object detection
X_train = load_sensor_data()  # Features
y_train = load_labels()       # Classes

clf = RandomForestClassifier(n_estimators=100)
clf.fit(X_train, y_train)

# Predict
sensor_reading = get_current_sensors()
prediction = clf.predict([sensor_reading])
```

### Reinforcement Learning

**Q-Learning Example**:
```python
import numpy as np

class QLearningRobot:
    def __init__(self, states, actions, learning_rate=0.1, discount=0.9):
        self.q_table = np.zeros((states, actions))
        self.lr = learning_rate
        self.gamma = discount
    
    def choose_action(self, state, epsilon=0.1):
        if np.random.random() < epsilon:
            return np.random.randint(len(self.q_table[state]))
        return np.argmax(self.q_table[state])
    
    def update(self, state, action, reward, next_state):
        current_q = self.q_table[state][action]
        max_next_q = np.max(self.q_table[next_state])
        new_q = current_q + self.lr * (reward + self.gamma * max_next_q - current_q)
        self.q_table[state][action] = new_q
```

**Deep Q-Learning (DQN)**:
- Neural network approximates Q-function
- Handles high-dimensional states
- Used in game-playing robots

### Computer Vision

**OpenCV - Object Detection**:
```python
import cv2

# Load pre-trained model
net = cv2.dnn.readNetFromCaffe('deploy.prototxt', 'model.caffemodel')

# Detect objects in image
blob = cv2.dnn.blobFromImage(frame, 0.007843, (300, 300), 127.5)
net.setInput(blob)
detections = net.forward()

for i in range(detections.shape[2]):
    confidence = detections[0, 0, i, 2]
    
    if confidence > 0.5:
        class_id = int(detections[0, 0, i, 1])
        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
        (x, y, x2, y2) = box.astype("int")
        
        cv2.rectangle(frame, (x, y), (x2, y2), (0, 255, 0), 2)
```

**YOLO (You Only Look Once)**:
- Real-time object detection
- Single neural network pass
- Fast enough for robotics

## Behavior Trees

Modular approach to robot decision-making.

```python
class BehaviorNode:
    SUCCESS = 1
    FAILURE = 0
    RUNNING = 2

class Sequence(BehaviorNode):
    """Executes children in order until one fails"""
    def __init__(self, children):
        self.children = children
    
    def tick(self):
        for child in self.children:
            result = child.tick()
            if result != self.SUCCESS:
                return result
        return self.SUCCESS

class Selector(BehaviorNode):
    """Tries children until one succeeds"""
    def __init__(self, children):
        self.children = children
    
    def tick(self):
        for child in self.children:
            result = child.tick()
            if result != self.FAILURE:
                return result
        return self.FAILURE

# Example: Robot patrol behavior
patrol_behavior = Selector([
    Sequence([
        CheckBattery(),
        GotoChargingStation(),
        Charge()
    ]),
    Sequence([
        CheckForIntruder(),
        FollowIntruder(),
        AlertOperator()
    ]),
    Sequence([
        GotoNextWaypoint(),
        Wait(5)
    ])
])
```

## Finite State Machines (FSM)

```python
from enum import Enum

class RobotState(Enum):
    IDLE = 1
    SEARCHING = 2
    APPROACHING = 3
    GRASPING = 4
    RETURNING = 5

class PickAndPlaceRobot:
    def __init__(self):
        self.state = RobotState.IDLE
    
    def update(self):
        if self.state == RobotState.IDLE:
            if self.task_received():
                self.state = RobotState.SEARCHING
        
        elif self.state == RobotState.SEARCHING:
            self.search_for_object()
            if self.object_found():
                self.state = RobotState.APPROACHING
        
        elif self.state == RobotState.APPROACHING:
            self.move_to_object()
            if self.reached_object():
                self.state = RobotState.GRASPING
        
        elif self.state == RobotState.GRASPING:
            self.grasp_object()
            if self.object_grasped():
                self.state = RobotState.RETURNING
        
        elif self.state == RobotState.RETURNING:
            self.return_to_base()
            if self.at_base():
                self.release_object()
                self.state = RobotState.IDLE
```

## Neural Networks for Control

**End-to-End Learning**:
```python
import tensorflow as tf

# Neural network that maps camera image to steering angle
model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(24, (5, 5), strides=(2, 2), activation='relu'),
    tf.keras.layers.Conv2D(36, (5, 5), strides=(2, 2), activation='relu'),
    tf.keras.layers.Conv2D(48, (5, 5), strides=(2, 2), activation='relu'),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(100, activation='relu'),
    tf.keras.layers.Dense(50, activation='relu'),
    tf.keras.layers.Dense(10, activation='relu'),
    tf.keras.layers.Dense(1)  # Steering angle output
])

model.compile(optimizer='adam', loss='mse')

# Train on collected data
model.fit(images, steering_angles, epochs=10, batch_size=32)

# Use for control
steering = model.predict(camera_image)
```

## Natural Language Processing

**Voice Commands**:
```python
import speech_recognition as sr

recognizer = sr.Recognizer()

def process_voice_command():
    with sr.Microphone() as source:
        print("Listening...")
        audio = recognizer.listen(source)
    
    try:
        command = recognizer.recognize_google(audio)
        
        if "move forward" in command.lower():
            robot.move_forward()
        elif "turn left" in command.lower():
            robot.turn_left()
        elif "stop" in command.lower():
            robot.stop()
        
    except sr.UnknownValueError:
        print("Could not understand audio")
```

## Decision Making Frameworks

### Utility Theory

```python
def choose_action(robot_state, possible_actions):
    best_action = None
    best_utility = -float('inf')
    
    for action in possible_actions:
        # Calculate utility based on multiple factors
        utility = (
            0.4 * battery_utility(robot_state, action) +
            0.3 * goal_distance_utility(robot_state, action) +
            0.2 * safety_utility(robot_state, action) +
            0.1 * energy_efficiency_utility(robot_state, action)
        )
        
        if utility > best_utility:
            best_utility = utility
            best_action = action
    
    return best_action
```

### Probabilistic Planning (POMDP)

Partially Observable Markov Decision Process - handles uncertainty.

## Swarm Intelligence

**Simple Swarm Algorithm**:
```python
class SwarmRobot:
    def __init__(self, position):
        self.position = position
        self.velocity = np.random.rand(2)
    
    def update(self, neighbors, goal):
        # Separation: Avoid crowding
        separation = self.separate(neighbors)
        
        # Alignment: Match velocity with neighbors
        alignment = self.align(neighbors)
        
        # Cohesion: Move towards center of neighbors
        cohesion = self.cohere(neighbors)
        
        # Goal seeking
        goal_force = (goal - self.position) * 0.1
        
        # Combine behaviors
        self.velocity += separation + alignment + cohesion + goal_force
        self.velocity = self.limit_velocity(self.velocity, max_speed=1.0)
        self.position += self.velocity
```

## Multi-Agent Systems

**Auction-Based Task Allocation**:
```python
class TaskAuction:
    def __init__(self, robots, tasks):
        self.robots = robots
        self.tasks = tasks
    
    def allocate_tasks(self):
        allocation = {}
        
        for task in self.tasks:
            bids = {}
            
            # Each robot bids
            for robot in self.robots:
                cost = robot.calculate_cost(task)
                bids[robot] = cost
            
            # Assign to lowest bidder
            winner = min(bids, key=bids.get)
            allocation[task] = winner
        
        return allocation
```

## Ethical AI Considerations

⚠️ **Important**:

1. **Safety First**: Fail-safe behaviors
2. **Transparency**: Explainable decisions
3. **Bias Mitigation**: Diverse training data
4. **Privacy**: Respect user data
5. **Human Override**: Always allow manual control

## Integration Example

```python
class AutonomousRobot:
    def __init__(self):
        self.vision_model = load_vision_model()
        self.behavior_tree = build_behavior_tree()
        self.q_learning = QLearningRobot(100, 4)
    
    def run(self):
        while True:
            # Perception
            image = self.camera.capture()
            objects = self.vision_model.detect(image)
            
            # Decision making
            self.behavior_tree.tick()
            
            # Learning
            state = self.get_state()
            action = self.q_learning.choose_action(state)
            reward = self.execute_action(action)
            next_state = self.get_state()
            self.q_learning.update(state, action, reward, next_state)
```
